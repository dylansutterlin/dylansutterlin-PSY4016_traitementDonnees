{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "# PSY 4016 / 6973\n",
    "# Cueillette et traitement des données en neurosciences cognitives\n",
    "## Chapitre 6: Stats. Scikit-Learn\n",
    "<p>\n",
    "<li>Évaluation statistique:<ul>\n",
    "    <li>Pandas\n",
    "    <li>SciPy\n",
    "    <li>Statsmodels\n",
    "    <li>Seaborn\n",
    "<li>Scikit-Learn: Pré-traitement</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b><h2>Évaluation statistique</h2></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "cerveau_df = pandas.read_csv('https://scipy-lectures.org/_downloads/brain_size.csv',\n",
    "                             sep=';',\n",
    "                             na_values='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerveau_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerveau_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_genre = cerveau_df.groupby('Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre la moyenne:\n",
    "\n",
    "groupby_genre.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre, valeur in groupby_genre['VIQ']:\n",
    "    print(genre, valeur.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerveau_df['FSIQ'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.plotting.scatter_matrix(\n",
    "        cerveau_df[['Weight','Height','MRI_Count']]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.plotting.scatter_matrix(\n",
    "    cerveau_df[['PIQ','VIQ','FSIQ']]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerveau_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    nous pouvons voir que les métriques de QI sont bimodales, comme il y a deux populations.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3> SciPy </h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li> auteur original: <b>Travis Oliphant, Pearu Peterson, Eric Jones</b>\n",
    "<li> Première version: <b>2001</b>\n",
    "<li> dernière version: <b>1.6.1, 17 février 2021</b>\n",
    "<li>https://github.com/scipy/scipy</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "si scipy n'est pas installé, dans le terminal, écrivez:\n",
    "> pip3 install scipy\n",
    "> pip3 install scipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Tester la normlité</h4>\n",
    "<li> scipy.stats.skew()\n",
    "<li> scipy.stats.kurtosis()\n",
    "<li>https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.skew(cerveau_df['VIQ']),\n",
    "      stats.kurtosis(cerveau_df['VIQ']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Un jeu de données symétrique () avec une distribution normale)\n",
    "aura une asymétrie égale à 0 (skew)\n",
    "\n",
    "Si l'aplatissement (kurtosis) est supérieur à 3, l'ensemble de données a des queues plus lourdes qu'une distribution normale (plus dans les queues)\n",
    "\n",
    "Si l'aplatissement est inférieur à 3, l'ensemble de données a des queues plus légères qu'une distribution normale (moins dans les queues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Test-T, 1 échantillon</h4>\n",
    "<li> scipy.stats.ttest_1samp()\n",
    "<li> tester la valeur d'une moyenne de population\n",
    "<li> (techniquement si les observations sont tirées d'une distribution gaussienne\n",
    "d'une moyenne de population donnée)\n",
    "<li> https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html\n",
    "<li>Renvoie:<ol>\n",
    "    <li>la statistique T \n",
    "    <li>la valeur de p</ol></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(cerveau_df['VIQ'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.ttest_1samp(cerveau_df['VIQ'], 0)\n",
    "print(res.statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li> il est possible de tester si la moyenne de population des données est susceptible \n",
    "d'être égale à une valeur donnée\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Avec une valeur de p de 10 ^ -28, nous pouvons affirmer que la moyenne de la population pour l'IQ (mesure VIQ) n'est pas 0</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Test-T, 2 échantillon</h4>\n",
    "<li> scipy.stats.ttest_ind()\n",
    "<li> ttest_ind va calculer le test T pour les moyennes de deux échantillons INDÉPENDANTS\n",
    "<li> tester la différence entre les populations\n",
    "<li> ttest_1samp a montré que le VIQ moyen dans les populations femmes et hommes était différent\n",
    "<li> ttest_ind va montrer si cela est significatif\n",
    "<li>Renvoie:<ol>\n",
    "    <li>la statistique T \n",
    "    <li>la valeur de p</ol></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "femme_viq = cerveau_df[cerveau_df['Gender'] == 'Female']['VIQ']\n",
    "homme_viq = cerveau_df[cerveau_df['Gender'] == 'Male']['VIQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(femme_viq, homme_viq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.ttest_ind(femme_viq, homme_viq)\n",
    "print(res.statistic, res.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Tests appariés: mesures répétées sur les mêmes individus</h4>\n",
    "<li> scipy.stats.ttest_ind()\n",
    "<li> PIQ, VIQ et FSIQ donnent 3 mesures de QI\n",
    "<li> pour tester si FISQ et PIQ sont significativement différents, il faudrait faire un test à 2 échantillons:\n",
    "<li> nous testerons d'abord en faisant l'hypothèse que les valeurs FSIQ et PIQ sont indépendantes\n",
    "<li>Renvoie:<ol>\n",
    "    <li>la statistique T \n",
    "    <li>la valeur de p</ol></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(cerveau_df['FSIQ'],\n",
    "                cerveau_df['PIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Tests appariés: mesures répétées sur les mêmes individus</h4>\n",
    "<li> scipy.stats.ttest_rel()\n",
    "<ul><li>les observations: FSIQ et PIQ sont mesurés sur les mêmes individus\n",
    "    <li> c'est un problème, parce que il existe des liens entre les deux variables\n",
    "<li>la variance due à la variabilité inter-sujets est source de confusion\n",
    "<li> cette variance peut être supprimée à l'aide d'un «test apparié»\n",
    "<li> un test t sur deux échantillons LIÉS (related) </ul>\n",
    "<li> nous testerons maintenant en faisant l'hypothèse que les valeurs FSIQ et PIQ sont LIÉS\n",
    "<li>Renvoie:<ol>\n",
    "    <li>la statistique T \n",
    "    <li>la valeur de p</ol></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(cerveau_df['FSIQ'],\n",
    "                cerveau_df['PIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Test de rang signé</h4>\n",
    "<ul>\n",
    "    <li> apparié: scipy.stats.wilcoxon() <b>Wilcoxon</b>\n",
    "    <li> non-apparié: scipy.stats.mannwhitneyu() <b>Mann-Whitney</b></ul>\n",
    "\n",
    "<ul><li>Les tests T supposent des erreurs gaussiennes\n",
    "    <li>le test de rang signé de Wilcoxon, peut assouplir cette hypothèse</ul>\n",
    "<li>Renvoie:<ol>\n",
    "    <li>la statistique T \n",
    "    <li>la valeur de p</ol></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(cerveau_df['FSIQ'],\n",
    "               cerveau_df['PIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Comment pouvons-nous effectuer une analyse statistique plus complexe:\n",
    "<ul>\n",
    "<li>Modèles linéaires, facteurs multiples et analyse de variance?\n",
    "<li>Une régression linéaire simple?\n",
    "<li>Étant donné deux ensembles d'observations, x et y, comment tester l'hypothèse que y est une fonction linéaire de x?</ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3> statsmodels </h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li> auteur original: <b>Jonathan Taylor</b>\n",
    "<li> Première version: <b>2009</b>\n",
    "<li> dernière version: <b>0.12.2</b>, 2 février 2021\n",
    "<li> construit sur la base de NumPy, SciPy, Pandas, Matplotlib\n",
    "<li>https://www.statsmodels.org/stable/index.html</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "statsmodels.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols #Ordinary Least Squares\n",
    "\n",
    "# https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html\n",
    "    \n",
    "# ols(\"y ~ x\", pandas.DataFrame).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"FSIQ ~ PIQ\", cerveau_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li>Statsmodels utilise une terminologie statistique:\n",
    "<li>la variable y dans les modèles statistiques est appelée «endogène»: la valeur que vous essayez de prédire\n",
    "\n",
    "<li>la variable x est appelée exogène: représente les fonctionnalités que vous utilisez pour effectuer la prédiction\n",
    "\n",
    "<li>en détail ici: http://www.statsmodels.org/devel/endog_exog.html</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerveau_df.Gender"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Variables catégorielles: \n",
    "comparaison de groupes ou de plusieurs catégories\n",
    "\n",
    "Nous pouvons écrire une comparaison entre \n",
    "le QI des hommes et des femmes \n",
    "en utilisant un modèle linéaire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variables catégorielles: \\ncomparaison de groupes ou de plusieurs catégories\\n\\nNous pouvons écrire une comparaison entre \\nle QI des hommes et des femmes \\nen utilisant un modèle linéaire:\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intercept: nous pouvons supprimer l'intercept \n",
    "# en utilisant - 1 dans la formule,\n",
    "# ou forcer l'utilisation d'une intercept en utilisant + 1.\n",
    "\n",
    "model = ols(\"VIQ ~ Gender + 1\", cerveau_df).fit()\n",
    "\n",
    "# le «genre» est automatiquement détecté comme une variable catégorielle,\n",
    "# et donc chacune de ses différentes valeurs est traitée\n",
    "# comme des entités différentes.\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une colonne entière peut être forcée d'être traitée \n",
    "# comme catégorique en utilisant la lettre C:\n",
    "\n",
    "model = ols(\"VIQ ~ C(Gender)\", cerveau_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li>Par défaut, les modèles statistiques traitent une variable catégorielle avec K valeurs possibles comme K-1 variables booléennes «factices» (le dernier niveau étant absorbé dans le terme d'interception). <li>C'est presque toujours un bon choix par défaut - cependant, il est possible de spécifier différents encodages pour les variables catégorielles (http://statsmodels.sourceforge.net/devel/contrasts.html)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Régression multiple: incluant plusieurs facteurs</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pandas.read_csv(\"https://scipy-lectures.org/_downloads/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25132/186680020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'iris' is not defined"
     ]
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['name']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* La taille des sépales (sepal_width)\n",
    "* et des pétales (petal_length)\n",
    "a tendance à être liée:\n",
    "les fleurs plus grosses ont des pétales plus grosses!\n",
    "\n",
    "* Mais y a-t-il en plus un effet systématique des espèces? (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('sepal_width ~ name + petal_length', iris).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Test d'hypothèse post-hoc: analyse de variance (ANOVA)</h4><p>\n",
    "\n",
    "<li> https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.f_test.html\n",
    "<li>nous souhaitons tester:<ol>\n",
    "    <li>si la LONGueur des PÉTales est différente entre: (petal_length)<ul>\n",
    "        <li>le versicolor et\n",
    "        <li>le virginica</ul>\n",
    "    <li>après avoir supprimé l'effet de la LARGeur des SÉPales (sepal_width).</ol>\n",
    "\n",
    "<li>Cela peut être formulé comme:<ol>\n",
    "    <li>testant la différence entre le coefficient associé au:<ul>\n",
    "        <li>versicolor et au\n",
    "        <li>virginica</ul>\n",
    "    <li>dans le modèle linéaire estimé</ol>\n",
    "<li>il s'agit d'une analyse de variance, ANOVA</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('sepal_width ~ name + petal_length', iris).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li>Pour cela, nous écrivons un vecteur de «contraste» sur les paramètres estimés:\n",
    "<li>pour tester avec un test F:\n",
    "    <li>«T.versicolor - T.virginica» (la différence)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Intercept      T.versicolor      T.virginica    petal_length\n",
    "Objectif:                    >\n",
    "    0                1                -1              0\n",
    "   0.5              0.5              -0.5            -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.f_test([0, 1, -1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Commment tester les interactions</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "            'http://lib.stat.cmu.edu/datasets/CPS_85_Wages',\n",
    "            'wages.txt')\n",
    "\n",
    "salaire = pandas.read_csv('wages.txt',\n",
    "                            skiprows = 27, skipfooter = 6, sep = None,\n",
    "                            header = None,\n",
    "                            names = ['education', 'gender', 'wage'],\n",
    "                            usecols = [0, 2, 5],\n",
    "                            engine = 'python'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaire.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot permet de tracer une\n",
    "# régression univariée\n",
    "\n",
    "# voici une régression saisissant\n",
    "# la relation entre une variable et une autre\n",
    "# par exemple le salaire et l'éducation\n",
    "\n",
    "sns.lmplot(y = 'wage',\n",
    "           x = 'education',\n",
    "           data = salaire)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pour regarder les interactions\n",
    "entre les variables continues\n",
    "il est possible d'utiliser\n",
    "seaborn.pairplot ()\n",
    "pour afficher une matrice de dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(salaire,\n",
    "             vars = ['wage', 'gender', 'education'],\n",
    "             kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les variables catégorielles peuvent être tracées comme teinte:\n",
    "\n",
    "sns.pairplot(salaire,\n",
    "             vars=['wage', 'education'],\n",
    "                kind = 'reg', hue = 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(y = 'wage',\n",
    "           x = 'education',\n",
    "           hue = 'gender',\n",
    "           data = salaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li>Les salaires augmentent-ils davantage avec l'éducation des hommes que des femmes?\n",
    "\n",
    "<li>L'intrigue ci-dessus est composée de deux ajustements différents. Nous devons formuler un modèle unique qui teste la variance de la pente entre les deux populations. Cela se fait via une «interaction».</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ols(formula = 'wage ~ education + gender',\n",
    "                data=salaire).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "les résultats ci-dessus soulignent qu'il y a une compensation différente des salaires par education et par genre</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'wage ~ education + gender + education * gender'\n",
    "\n",
    "model_anova = ols(formula = formula,\n",
    "                  data = salaire).fit()\n",
    "\n",
    "print(model_anova.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_anova.pvalues.loc['education:gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Pouvons-nous conclure que l'éducation profite plus aux hommes qu'aux femmes?\n",
    "\n",
    "<li>la valeur de p de l'interaction entre le sexe et l'éducation\n",
    "<li>education:gender\n",
    "<li>ne soutiennent pas l'hypothèse selon laquelle l'éducation profite davantage aux hommes qu'aux femmes (valeur de p> 0,05)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b><h2>Scikit-Learn</h2></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li> auteur original: <b>David Cournapeau</b>\n",
    "<li> Première version: <b>Juin 2007</b>\n",
    "<li> dernière version: <b>0.24.1</b>, janvier 2021\n",
    "<li> noyau: a été initialement développé comme une extension de SciPy\n",
    "<li> Leadership actuel (INRIA - Institut national de recherche en informatique et en automatique, Rocquencourt, France)\n",
    "    <ol>\n",
    "        <li><b>Fabian Pedregosa</b><li><b>Gael Varoquaux</b><li><b>Alexandre Gramfort</b><li><b>Vincent Michel</b> </ol></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Prétraitement des données</h3>\n",
    "    <ul>\n",
    "        <li>les données nécessitent plusieurs étapes d'ajustements avant de pouvoir être analysées.\n",
    "        <li>ces étapes sont généralement appelées - prétraitement.\n",
    "        <li>certaines des étapes courantes de prétraitement sont:<ol>\n",
    "            <li>encodage d'étiquette\n",
    "            <li>normalisation des données (mise à l'échelle)\n",
    "            <li>imputation des valeurs manquantes</ol>\n",
    "        <li>pour cela nous pouvons utiliser le module: <b>sklearn.preprocessing</b> et <b>sklearn.impute</b></ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code écrit pour sklearn.__version__ == 0.24.1\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3> encodage/ binarisation d'étiquette </h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h5>sklearn.preprocessing.LabelEncoder()</h5>\n",
    "<li>permet d'encodez les étiquettes cibles avec une valeur comprise entre 0 et n_classes-1\n",
    "<li>https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder est une classe,\n",
    "# pour l'utiliser, il est plus facile de l'instancier.\n",
    "\n",
    "# le = sklearn.preprocessing.LabelEncoder()\n",
    "\n",
    "# Alternativement:\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialement, les données doivent être adaptées au codeur d'étiquettes.\n",
    "\n",
    "le.fit(iris.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# après cela, les étiquettes peuvent être transformées en codage normalisé.\n",
    "\n",
    "le.transform(iris.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativement, les étiquettes peuvent être ajustées à l'encodeur\n",
    "# et transformées avec une seule commande. \n",
    "\n",
    "le.fit_transform(iris.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3> normalisation des données </h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Importance de la mise à l'échelle des fonctionnalités </h4>\n",
    "<li> Normalisation = redimensionnement des entités de sorte qu'elles aient les propriétés d'une <b>distribution normale standard</b> avec une <b>moyenne de zéro et un écart type de un</b>\n",
    "\n",
    "<li> La mise à l'échelle des fonctionnalités (normalisation du score Z) peut être importante ou même requise pour de nombreux algorithmes AA (tels que PCA, SVM, KNN et régression logistique)\n",
    "<li>la normalisation permet la suppression des valeurs aberrantes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Exemples d'algorithmes de transformation linéaire gaussienne</h4>\n",
    "    <li>sklearn.preprocessing.StandardScaler()\n",
    "    <li>sklearn.preprocessing.RobustScaler()\n",
    "    <li>pour plus d'informations sur la normalisation et la comparaison des échelles:\n",
    "    <li> https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = iris[[\"sepal_length\",\n",
    "               \"sepal_width\",\n",
    "               \"petal_length\",\n",
    "               \"petal_width\"]]\n",
    "\n",
    "scaled = scaler.fit(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = scaler.transform(X_data)\n",
    "# transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scale only one column:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_one = iris.sepal_length.to_numpy()\n",
    "x_one = x_one[:, np.newaxis]\n",
    "scaled_one = scaler.fit(x_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li>Si les données contiennent de nombreuses valeurs aberrantes, la mise à l'échelle à l'aide de la moyenne et de la variance des données ne fonctionnera probablement pas très bien\n",
    "<li>Dans ces cas, RobustScaler utilise des estimations plus robustes pour le centre et la plage de vos données.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>Exemples d'algorithmes de transformation non-linéaire non-gaussienne</h4>\n",
    "    <li>sklearn.preprocessing.QuantileTransformer()\n",
    "    <li>sklearn.preprocessing.PowerTransformer()\n",
    "    <li>les deux algorithm sont basées sur des transformations monotones des entités (ligne ou colonnes) et maintienent le rang des valeurs le long de chaque entité\n",
    "    <li>cependant, le QuantileTransformer() déforme les corrélations et les distances à l'intérieur et entre les entités.\n",
    "    <li>Les PowerTransformer est une famille de transformations paramétriques qui visent à mapper les données de n'importe quelle distribution à une distribution gaussienne aussi proche que possible.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.QuantileTransformer()\n",
    "\n",
    "X_iris = iris[[\"sepal_length\",\n",
    "               \"sepal_width\",\n",
    "               \"petal_length\",\n",
    "               \"petal_width\"]]\n",
    "X_scaled = scaler.fit_transform(X_iris)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris_arr = X_iris.to_numpy()\n",
    "\n",
    "print(np.percentile(X_iris_arr[:, 0], [0, 25, 50, 75, 100]))\n",
    "print(np.percentile(  X_scaled[:, 0], [0, 25, 50, 75, 100]))\n",
    "\n",
    "# Une fois la QuantileTransformer appliquée,\n",
    "# ces repères se rapprochent étroitement\n",
    "# des centiles précédemment définis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3> Imputation des valeurs manquantes </h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<li>scikit-learn suppose que toutes les valeurs sont numériques et ont toutes une signification. Les données manquantes sont incompatibles avec scikit-learn.\n",
    "\n",
    "<li> de nombreux ensembles de données du monde réel contiennent des valeurs manquantes, souvent codées sous forme de blancs, de NaN ou d'autres espaces réservés.\n",
    "\n",
    "<li> Lorsque des données sont manquantes, une stratégie de base consiste à supprimer des lignes entières et / ou des colonnes contenant des valeurs manquantes.\n",
    "\n",
    "<li> Une meilleure stratégie consiste à imputer les valeurs manquantes, c'est-à-dire à les déduire de la partie connue des données.\n",
    "<li>https://scikit-learn.org/stable/modules/impute.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>L'algorithme d'imputation univarié: sklearn.impute.SimpleImputer</h4>\n",
    "<li>impute des valeurs dans la n-ième dimension d'entité (ligne, colonne)\n",
    "<li>en utilisant uniquement les valeurs non manquantes dans cette dimension d'entité (ligne, colonne)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = impute.SimpleImputer(missing_values = np.nan,\n",
    "                           strategy = \"mean\")\n",
    "\n",
    "#median, most_frequent, constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier = 'https://scipy-lectures.org/_downloads/brain_size.csv'\n",
    "cerveau_df = pandas.read_csv(fichier,\n",
    "                             sep=';',\n",
    "                             na_values='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y a-t-il des valeurs manquantes?\n",
    "\n",
    "cerveau_df.Height.isnull().any(), cerveau_df.Weight.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouvons l'index de la colonne avec des données manquantes\n",
    "X_data = cerveau_df[[\"Weight\", \"Height\"]]\n",
    "\n",
    "ix = X_data.Height[X_data.Height.isnull()].index.tolist()[0]\n",
    "X_data.iloc[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.fit(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = imp.transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention! les données résultantes sont au format numpy\n",
    "\n",
    "X_new[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changeons pour la valeur la plus fréquente. \n",
    "\n",
    "imp = sklearn.impute.SimpleImputer(missing_values = np.nan,\n",
    "                                   strategy = \"most_frequent\")\n",
    "imp.fit(X_data)\n",
    "X_new = imp.transform(X_data)\n",
    "X_new[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>les commandes et codes à apprendre par cœur </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANDAS:\n",
    "    pandas.read_csv(filepath, sep=<object>, header=None, \n",
    "                    names=['col1', 'col2'], usecols=[0, 2, 5],\n",
    "                    skiprows=27, skipfooter=6, na_values='.'\n",
    "                       ) # sep = ';', sep = None, na_values = None\n",
    "SCIPY:\n",
    "    scipy.stats.ttest_1samp(pandas.DataFrame['col_y'], 0)\n",
    "    scipy.stats.ttest_ind(pandas.DataFrame['col_y'], pandas.DataFrame['col_x'])\n",
    "    scipy.stats.ttest_rel(pandas.DataFrame['col_y'], pandas.DataFrame['col_x'])\n",
    "    scipy.stats.wilcoxon(pandas.DataFrame['col_y'], pandas.DataFrame['col_x'])\n",
    "    \n",
    "STATSMODELS:\n",
    "    from statsmodels.formula.api import ols #Ordinary Least Squares    \n",
    "    ols(\"col_y ~ col_x\", pandas.DataFrame).fit()\n",
    "    ols(\"col_y ~ col_group + 1\", pandas.DataFrame).fit()\n",
    "    ols(\"col_y ~ C(col_group)\", pandas.DataFrame).fit()\n",
    "    model = ols('col_y ~ col_group + col_x', pandas.DataFrame).fit()\n",
    "        model.rsquared_adj\n",
    "        model.fvalue\n",
    "        model.f_pvalue\n",
    "        model.params\n",
    "        model.tvalues\n",
    "        model.pvalues\n",
    "        model.pvalues[0]\n",
    "        model.pvalues[\"Intercept\"]\n",
    "        model.pvalues.loc['Intercept']\n",
    "        model.f_test([0, 1, -1, 0]))\n",
    "    \n",
    "SKLEARN:\n",
    "    sklearn.preprocessing.LabelEncoder()\n",
    "        fit_transform(pandas.DataFrame['col_y'])\n",
    "    sklearn.preprocessing.StandardScaler()\n",
    "        fit(pandas.DataFrame['col_x1', 'col_x2'])\n",
    "        transform(pandas.DataFrame['col_x1', 'col_x2'])\n",
    "        \n",
    "        one_feat = pandas.DataFrame['col_x1'].to_numpy()\n",
    "        one_feat = one_feat[:, np.newaxis]\n",
    "        fit(one_feat)\n",
    "        transform(one_feat)        \n",
    "    sklearn.preprocessing.QuantileTransformer()\n",
    "        fit_transform(pandas.DataFrame)\n",
    "    sklearn.impute.SimpleImputer(missing_values = np.nan,\n",
    "                                 strategy = \"mean\")\n",
    "                                # strategy = median,\n",
    "                                # most_frequent,\n",
    "                                # constant\n",
    "        fit(pandas.DataFrame)\n",
    "        transform(pandas.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h4>Exercices</h4><p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<ol start=1><li>list (poids = 0.5, durée suggéree: 2min)\n",
    "<ul><li>quelles sont les méthodes utilisées pour rechercher les valeurs manquantes\n",
    "</ul></ol></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<ol start=2><li>list (poids = 0.8, durée suggéree: 5min)\n",
    "<ul><li>utiliser l'algorithme SimpleImputer, mais avec les méthodes disponibles dans d'autres bibliothèques\n",
    "</ul></ol></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<ol start=3><li>list (poids = 2, durée suggéree: 15min)\n",
    "<ul><li>cadre de données cerveau: cerveau_df = pandas.read_csv('https://scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values='.')\n",
    "<li> Testez la différence entre les poids des cerveau des femmes et des hommes\n",
    "<li> Utilisez des statistiques non paramétriques pour tester la différence entre le VIQ chez les hommes et les femmes.\n",
    "<li>créer le modèle à l'aide de statsmodels\n",
    "<li> Récupérez les paramètres estimés du modèle.\n",
    "<li>Astuce: utilisez la saisie TAB, semi-automatique pour trouver l'attribut pertinent.\n",
    "</ul></ol></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
